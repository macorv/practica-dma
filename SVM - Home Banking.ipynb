{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/seaborn/apionly.py:6: UserWarning: As seaborn no longer sets a default style on import, the seaborn.apionly module is deprecated. It will be removed in a future version.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn.apionly as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el Archivo de Home Banking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_banking = pd.read_excel(r'E:\\Univ. Austral\\Ferola Laboratorio\\Libro4.xlsx')\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "home_banking.columns\n",
    "\n",
    "X=home_banking[[ 'pred','finde', 'feriado','posferiado', 'habil', 'primer_habil', 'ultimo_habil']]\n",
    "\n",
    "y=home_banking['obs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coeficientes\n",
    "\n",
    "Explicacion\n",
    "coef:\n",
    "degree:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVR(C=99999999.0,  epsilon=50000, gamma=30,  kernel='rbf' )\n",
    "\n",
    "clf.fit(X, y)\n",
    "ee=clf.predict(X)\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "#Genero el tiempo\n",
    "\n",
    "t=[i for i in range(0,len(ee))]\n",
    "\n",
    "#Grafico\n",
    "\n",
    "bg_color = 'white'\n",
    "\n",
    "fg_color = 'black'\n",
    "\n",
    "fig = plt.figure(1,figsize=(5,5),facecolor=bg_color, edgecolor=fg_color)\n",
    "\n",
    "plt.figure(1,figsize=(5,5),axisbg='red')\n",
    "\n",
    "axes = plt.axes((0.1, 0.1, 0.8, .8), axisbg=bg_color)\n",
    "\n",
    "axes.xaxis.set_tick_params(color=fg_color, labelcolor=fg_color)\n",
    "\n",
    "axes.yaxis.set_tick_params(color=fg_color, labelcolor=fg_color)\n",
    "\n",
    "axes.axhline(y=0, color='w')\n",
    "\n",
    "axes.axvline(x=0, color='w') \n",
    "\n",
    "axes.grid(True, which='both')\n",
    "\n",
    " \n",
    "\n",
    "for spine in axes.spines.values():\n",
    "\n",
    "    spine.set_color(fg_color)\n",
    "\n",
    "   \n",
    "\n",
    "#plot1=plt.plot(ee, y, c='y', linewidth=0.5,axes=axes)\n",
    "\n",
    "plot2=plt.scatter(ee,y,c='y',marker='.')\n",
    "\n",
    "plot3=plt.scatter(X['pred'],y,c='w',marker='.')\n",
    "\n",
    " \n",
    "\n",
    "plot2=plt.plot(t, ee, c='y', linewidth=0.5,axes=axes)\n",
    "\n",
    "plot3=plt.plot(t, y, c='w', linewidth=0.5,axes=axes)\n",
    "\n",
    "plot3=plt.plot(t, X['pred'], c='r', linewidth=0.5,axes=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformadas de Fourier / Hilbert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting\n",
    "\n",
    "\n",
    "Un SVM de un mismo dataset, siempre me va a dar lo mismo. Un arbol en cambio es mas inestable.\n",
    "\n",
    "El arbol se va a adaptar a diferentes muestras, en ese sentido, el boosting esta bueno.\n",
    "\n",
    "\n",
    "BINOMIAL\n",
    "Cantidad de ensayos, probabilidad y el resultado que quiero ver.\n",
    "\n",
    "B(probabilidad, cantidad de ensayos / lo que quiero probar)\n",
    "\n",
    "Por ejemplo, si quiero ver cual es la probabilidad que 12 arboles equivocandose al 60% de 20 ensayos. \n",
    "\n",
    "## Optimizacion\n",
    "Para optimizar hipermparametros\n",
    "\n",
    "Para datos tabulares (en tablas) se usan XGBoost o LightGBM (este ultimo es mas rapido).\n",
    "\n",
    "Para deep learning, se usas el paquete KERAS.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
