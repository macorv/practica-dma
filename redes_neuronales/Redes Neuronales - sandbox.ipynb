{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "Lugar para practicar y aprender redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los paquetes necesarios\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Componentes:\n",
    "# input_layer\n",
    "# hidden_layer\n",
    "# output_layer\n",
    "# weights - diccionario\n",
    "\n",
    "# Entrada de datos\n",
    "input_layer = np.array([2,3])\n",
    "\n",
    "# Pesos de la red\n",
    "weights = { 'node_0': np.array([1,1]), \n",
    "            'node_1': np.array([-1,1]),\n",
    "            'output': np.array([2,-1])}\n",
    "\n",
    "# Calculo de nodos\n",
    "node_0_value = (input_layer * weights['node_0']).sum()\n",
    "node_1_value = (input_layer * weights['node_1']).sum()\n",
    "\n",
    "# Array de Hidden Layer\n",
    "hidden_layer = np.array([node_0_value, node_1_value])\n",
    "\n",
    "output_value = (hidden_layer * weights['output']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de Activacion: la funcion ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set de Datos\n",
    "# [array([3, 5]), array([ 1, -1]), array([0, 0]), array([8, 4])]\n",
    "\n",
    "# Weights\n",
    "# {'node_0': array([2, 4]), 'node_1': array([ 4, -5]), 'output': array([2, 7])}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52, 63, 0, 148]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo con un dataset con 4 registros y 2 features\n",
    "\n",
    "# Datos\n",
    "weights = {'node_0': np.array([2, 4]), 'node_1': np.array([ 4, -5]), 'output': np.array([2, 7])}\n",
    "data_input = np.array([np.array([3, 5]), np.array([ 1, -1]), np.array([0, 0]), np.array([8, 4])])\n",
    "\n",
    "# Funcion ReLU\n",
    "def relu(input):\n",
    "    output = max (0, input)\n",
    "    return(output)\n",
    "\n",
    "# Definimos la funcion\n",
    "def neural_function(data_input_rows, weights):\n",
    "    \n",
    "    node_0_input = (data_input_rows*weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "    \n",
    "    node_1_input = (data_input_rows*weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "    \n",
    "    hidden_layer = np.array([node_0_output,node_1_output])\n",
    "    \n",
    "    hidden_layer_input = (hidden_layer*weights['output']).sum()\n",
    "    hidden_layer_output = relu(hidden_layer_input)\n",
    "    \n",
    "    return(hidden_layer_output)\n",
    "\n",
    "# Imprimimos los resultados\n",
    "results = []\n",
    "\n",
    "for data_input_rows in data_input:\n",
    "    results.append(neural_function(data_input_rows, weights))\n",
    "    # Tambien se puede usar -> results = results + [neural_function(data_input_rows, weights)]\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red Neuronal con 2 Hidden Layers\n",
    "\n",
    "# Hacer ejercicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizacion de una red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_function_identity(data_input_rows, weights):\n",
    "    '''Defino una red con funcion de identidad como Funcion de Acrtivacion'''\n",
    "    \n",
    "    node_0_input = (data_input_rows*weights['node_0']).sum()\n",
    "    node_1_input = (data_input_rows*weights['node_1']).sum()\n",
    "    \n",
    "    hidden_layer = np.array([node_0_input,node_1_input])\n",
    "    \n",
    "    hidden_layer_input = (hidden_layer*weights['output']).sum()\n",
    "    \n",
    "    return(hidden_layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 9, -9, 12]\n",
      "[9.75, 10.0, -10.0, 14.0]\n",
      "MSE with weights_0: 80.25\n",
      "MSE with weights_0: 99.89\n"
     ]
    }
   ],
   "source": [
    "input_data =[np.array([0, 3]), np.array([1, 2]), np.array([-1, -2]), np.array([4, 0])]\n",
    "weights_0 = {'node_0': np.array([2, 1]), 'node_1': np.array([1, 2]), 'output': np.array([1, 1])}\n",
    "weights_1 = {'node_0': np.array([2, 1]),'node_1': np.array([1. , 1.5]),'output': np.array([1. , 1.5])}\n",
    "target_actuals = [1, 3, 5, 7]\n",
    "\n",
    "predicted_0 = []\n",
    "predicted_1 = []\n",
    "\n",
    "for rows in input_data:\n",
    "    predicted_0.append(neural_function_identity(rows,weights_0))\n",
    "    predicted_1.append(neural_function_identity(rows,weights_1))\n",
    "\n",
    "print(predicted_0)\n",
    "print(predicted_1)\n",
    "\n",
    "mse_0 = mean_squared_error(target_actuals,predicted_0)\n",
    "mse_1 = mean_squared_error(target_actuals,predicted_1)\n",
    "\n",
    "print(f'MSE with weights_0: {mse_0:.2f}')\n",
    "print(f'MSE with weights_0: {mse_1:.2f}')\n",
    "\n",
    "# RESULTADOS EJERCICIO\n",
    "# Mean squared error with weights_0: 294.000000\n",
    "#Mean squared error with weights_1: 395.062500\n",
    "\n",
    "\n",
    "# Codigo para calcular slopes y actualizar pesos\n",
    "\n",
    "# weights [1,2]\n",
    "# input_data = [3,4]\n",
    "# target = 6\n",
    "# learning_rate = 0.01\n",
    "\n",
    "# calcular el error\n",
    "\n",
    "# gradient(es el calculo de la pendiente) = 2*error*input_data\n",
    "# weight actualizado = weight - gradient*learning_rate\n",
    "# despues hay que actualizar la prediccion y los errores de esa prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un modelo en keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Especificar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Importo lo necesario para construir nuestro modelo\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Importamos la data\n",
    "predictors = np.loadtxt('predictors_data.csv', delimiter=',')\n",
    "\n",
    "# Necesitamos especificar el numero de columnas porque es la cantidad de nodos que va en el input_layer\n",
    "n_cols = predictors.shape[1] \n",
    "\n",
    "\n",
    "# Construccion del Modelo\n",
    "\n",
    "# Hay varios tipos de modelos:\n",
    "# Sequential, Convolucionales, Recurrentes, etc.\n",
    "# Las secuenciales son las mas simples. Son secuenciales aquellas que tienen conexion con la capa subsiguiente.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Se agregan capas (layers) al modelo con la funcion 'add'\n",
    "# Dense layers: todos los nodos de la capa anterior tienen conexiones con todos los nodos de la capa posterior\n",
    "\n",
    "# model.add(Dense({cantidad_nodos}, {funcion_activacion}, {cantidad_columnas}))\n",
    "\n",
    "#input_layer\n",
    "model.add(Dense(100, activation='relu', input_shape= (n_cols,)))\n",
    "\n",
    "#hidden_layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "#output_layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# Compilacion del Modelo: defino el optimizador y la funcion de perdida\n",
    "# Adam es un algoritmo de optimizacion versatil\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# IMPORTANTE! Aun con el optimizador 'Adam', es recomendable NORMALIZAR ((X-mean)/Desvio Estandar) los datos \n",
    "\n",
    "# Ajuste del Modelo\n",
    "model.fit(predictors,target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
